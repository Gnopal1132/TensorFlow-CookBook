{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68472e64",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d82c0d9",
   "metadata": {},
   "source": [
    "PATH = os.path.join(os.curdir, \"Dataset\", \"MultiVariate Dataset\", \"pollution_multivariate.csv\")\n",
    "dataset = pd.read_csv(PATH)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7538de0b",
   "metadata": {},
   "source": [
    "dataset.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "126f6194",
   "metadata": {},
   "source": [
    "Assembling a datetime from multiple columns of a DataFrame. The keys can be common abbreviations like [‘year’, ‘month’, ‘day’, ‘minute’, ‘second’, ‘ms’, ‘us’, ‘ns’]) or plurals of the same example:   2015-09-03 10:53:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6ffa1e4",
   "metadata": {},
   "source": [
    "dataset[\"time\"] = dataset.year.astype(\"str\") + \"-\" + dataset.month.astype(\"str\") + \"-\" + dataset.day.astype(\"str\") + \" \" + dataset.hour.astype(\"str\")+':0:0'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49d6d11d",
   "metadata": {},
   "source": [
    "dataset.time = pd.to_datetime(dataset.time)\n",
    "dataset.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fcd2c9a",
   "metadata": {},
   "source": [
    "dataset.set_index(dataset['time'],inplace=True)\n",
    "dataset.drop([\"time\", \"No\"], axis=1, inplace=True)\n",
    "dataset.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d8dbd1e",
   "metadata": {},
   "source": [
    "dataset.info()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0510d166",
   "metadata": {},
   "source": [
    "dataset.describe()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eddeea2b",
   "metadata": {},
   "source": [
    "# Lets check the NULL Values first\n",
    "\n",
    "null = pd.DataFrame(dataset.isnull().sum()).rename(columns={0:\"Total\"})\n",
    "null['percentage'] = null['Total'] / len(dataset)\n",
    "null.sort_values('percentage',ascending=False).head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9556bb8d",
   "metadata": {},
   "source": [
    "# Lets see the distribution of pm2.5\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.kdeplot(dataset['pm2.5'], shade=True)\n",
    "# Very much right skewed"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5191f8e5",
   "metadata": {},
   "source": [
    "# Lets forward fill the points\n",
    "dataset = dataset.fillna(method='ffill')\n",
    "dataset.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "653f2919",
   "metadata": {},
   "source": [
    "# Still there are some null values lets fill them with the mean value\n",
    "meanvalue = dataset['pm2.5'].mean()\n",
    "dataset['pm2.5'] = dataset['pm2.5'].fillna(value=meanvalue)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0dba42d1",
   "metadata": {},
   "source": [
    "dataset.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b02685ce",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dataset.cbwd = LabelEncoder().fit_transform(dataset.cbwd)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8223c049",
   "metadata": {},
   "source": [
    "# Lets look at the distribution of values. They are all hourly distributed\n",
    "dataset = dataset.resample('H').mean()\n",
    "dataset.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b7b7fe1",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "for idx, col in enumerate(dataset.columns):\n",
    "    plt.subplot(len(dataset.columns), 1, idx+1)\n",
    "    plt.plot(dataset[col], label=col)\n",
    "    plt.legend()    \n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "86581ba5",
   "metadata": {},
   "source": [
    "train = dataset[ : int(len(dataset) * 0.7)]\n",
    "val = dataset[int(len(dataset) * 0.7) : int(len(dataset) * 0.9)]\n",
    "test = dataset[int(len(dataset) * 0.9):]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6898c27f",
   "metadata": {},
   "source": [
    "train.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7571d805",
   "metadata": {},
   "source": [
    "train_label = train.TEMP\n",
    "train_data = train.drop(['TEMP'], axis=1)\n",
    "\n",
    "val_label = val.TEMP\n",
    "val_data = val.drop(['TEMP'], axis=1)\n",
    "\n",
    "test_data = test.TEMP\n",
    "test_label = test.drop(['TEMP'], axis=1)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d7fb4fff",
   "metadata": {},
   "source": [
    "mean = train_data.mean()\n",
    "std = train_data.std()\n",
    "\n",
    "train_data = (train_data - mean) / std\n",
    "val_data = (val_data - mean) / std\n",
    "test_data = (test_data - mean) / std"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "52442ae5",
   "metadata": {},
   "source": [
    "train_data.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1cb1f039",
   "metadata": {},
   "source": [
    "def create_non_sequential_loader(series, labels, batchsize=32, buffersize=100):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((series, labels))\n",
    "    dataset = dataset.cache().shuffle(buffersize).batch(batchsize)\n",
    "    return dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "811d8e01",
   "metadata": {},
   "source": [
    "train_sequential = create_non_sequential_loader(train_data.to_numpy(), train_label.to_numpy())\n",
    "val_sequential = create_non_sequential_loader(val_data.to_numpy(), val_label.to_numpy())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8bcefd58",
   "metadata": {},
   "source": [
    "for X, Y in train_sequential.take(1):\n",
    "    print(X.shape)\n",
    "    print(Y.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "79d864c9",
   "metadata": {},
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[11]),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "39779a4f",
   "metadata": {},
   "source": [
    "model.compile(loss='mse', optimizer='adam')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e7900767",
   "metadata": {},
   "source": [
    "earlystop = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_temp/', save_best_only=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f54fdd94",
   "metadata": {},
   "source": [
    "history = model.fit(train_sequential, epochs=50, validation_data=val_sequential, callbacks=[earlystop, checkpoint])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8df7cd99",
   "metadata": {},
   "source": [
    "# Lets try sequential loader\n",
    "\n",
    "def create_non_sequential_loader(series, window_size=24, batchsize=32, buffersize=100):\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    dataset = dataset.window(window_size, drop_remainder=True, shift=1)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size))\n",
    "    dataset = dataset.map(lambda window: (window[:,:-1], window[-1,-1]), num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.cache().shuffle(buffersize).batch(batchsize)\n",
    "    return dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7fff3a4e",
   "metadata": {},
   "source": [
    "train = tf.concat([train_data.to_numpy(), train_label.to_numpy().reshape(-1,1)], axis=1)\n",
    "val = tf.concat([val_data.to_numpy(), val_label.to_numpy().reshape(-1,1)], axis=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eeebe240",
   "metadata": {},
   "source": [
    "train = create_non_sequential_loader(train)\n",
    "val = create_non_sequential_loader(val)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cfa2609e",
   "metadata": {},
   "source": [
    "for X, Y in train.take(1):\n",
    "    print(X.shape)\n",
    "    print(Y.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ce80c0f7",
   "metadata": {},
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=5, strides=1, padding='causal', activation='relu',\n",
    "                          input_shape=[None, 11]),\n",
    "    # This convnet can learn to detect short term patterns that are most useful for the RNN.\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "22265aee",
   "metadata": {},
   "source": [
    "model.compile(loss='mse', optimizer='adam')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "88aae27d",
   "metadata": {},
   "source": [
    "earlystop = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_temp/', save_best_only=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51bde94",
   "metadata": {},
   "source": [
    "history = model.fit(train, epochs=50, validation_data=val, callbacks=[earlystop, checkpoint])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a27bb65",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_deepai",
   "language": "python",
   "name": "tf2_deepai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
